{"id": 163, "title": "We\u2019re Still Waiting for the Next Big Leap in AI", "timestamp": "2024-06-20T13:42:50Z", "content": "To revisit this article, visit My Profile, then View saved stories.\nWhen OpenAI announced GPT-4, its latest large language model, last March, it sent shockwaves through the tech world. It was clearly more capable than anything seen before at chatting, coding, and solving all sorts of thorny problems\u2014including school homework.\nAnthropic, a rival to OpenAI, announced today that it has made its own AI advance that will upgrade chatbots and other use cases. But although the new model is the world\u2019s best by some measures, it\u2019s more of a step forward than a big leap.\nAnthropic\u2019s new model, called Claude 3.5 Sonnet, is an upgrade to its existing Claude 3 family of AI models. It is more adept at solving math, coding, and logic problems as measured by commonly used benchmarks. Anthropic says it is also a lot faster, better understands nuances in language, and even has a better sense of humor.\nThat\u2019s no doubt useful to people trying to build apps and services on top of Anthropic\u2019s AI models. But the company\u2019s news is also a reminder that the world is still waiting for another AI leap forward in AI akin to that delivered by GPT-4.Expectation has been building for OpenAI to release a sequel called GPT-5 for more than a year now, and the company\u2019s CEO, Sam Altman, has encouraged speculation that it will deliver another revolution in AI capabilities. GPT-4 cost more than $100 million to train, and GPT-5 is widely expected to be much larger and more expensive.\nAlthough OpenAI, Google, and other AI developers have released new models that out-do GPT-4, the world is still waiting for that next big leap. Progress in AI has lately become more incremental and more reliant on innovations in model design and training rather than brute-force scaling of model size and computation, as GPT-4 did.\nMichael Gerstenhaber, head of product at Anthropic, says the company\u2019s new Claude 3.5 Sonnet model is larger than its predecessor but draws much of its new competence from innovations in training. For example, the model was given feedback designed to improve its logical reasoning skills. Anthropic says that Claude 3.5 Sonnet outscores the best models from OpenAI, Google, and Facebook in popular AI benchmarks including GPQA, a graduate-level test of expertise in biology, physics, and chemistry; MMLU, a test covering computer science, history, and other topics; and HumanEval, a measure of coding proficiency. The improvements are a matter of a few percentage points though.This latest progress in AI might not be revolutionary but it is fast-paced: Anthropic only announced its previous generation of models three months ago. \u201cIf you look at the rate of change in intelligence you\u2019ll appreciate how fast we\u2019re moving,\u201d Gerstenhaber says.\nMore than a year after GPT-4 spurred a frenzy of new investment in AI, it may be turning out to be more difficult to produce big new leaps in machine intelligence. With GPT-4 and similar models trained on huge swathes of online text, imagery, and video, it is getting more difficult to find new sources of data to feed to machine-learning algorithms. Making models substantially larger, so they have more capacity to learn, is expected to cost billions of dollars. When OpenAI announced its own recent upgrade last month, with a model that has voice and visual capabilities called GPT-4o, the focus was on a more natural and humanlike interface rather than on substantially more clever problem-solving abilities.\nGauging the rate of progress in AI using conventional benchmarks like those touted by Anthropic for Claude can be misleading. AI developers are strongly incentivized to design their creations to score highly in these benchmarks, and the data used for these standardized tests can be swept into their training data. \u201cBenchmarks within the research community are riddled with data contamination, inconsistent rubrics and reporting, and unverified annotator expertise,\u201d says Summer Yue, research director at Scale AI, a company that helps many AI firms train their models.\nScale is developing new ways of measuring AI smarts through its Safety, Evaluations and Alignment Lab. This involves developing tests based on data that is kept secret and vetting the expertise of those who provide feedback on a model\u2019s capabilities.\nYue is hopeful that companies will increasingly seek to demonstrate their model\u2019s intelligence in more meaningful ways. She says those may include \u201cby showcasing real-world applications with measurable business impact, providing transparent performance metrics, case studies, and customer testimonials.\u201d\nAnthropic is touting such impacts for Claude 3.5 Sonnet. Gerstenhaber says that companies using the latest version have found its newfound responsiveness and problem-solving abilities beneficial. Customers include the investment firm Bridgewater Associates, which is using Claude to help with coding tasks. Some other financial firms, which Gerstenhaber declines to disclose, are using the model to provide investment advice. \u201cThe response during the early access period has been enormously positive,\u201d he says.\nIt\u2019s unclear how long the world must wait for that next big leap in AI. OpenAI has said it has started training its next big model. In the meantime, we will need to figure out new ways to measure how useful the technology really is.\nIn your inbox: Get Plaintext\u2014Steven Levy's long view on tech\nWelcome to the hellhole of programmatic advertising\nHow many EV charging stations does the US need to replace gas stations?\nA nonprofit tried to fix tech culture\u2014but lost control of its own\nIt's always sunny: Here are the best sunglasses for every adventure\nMore From WIRED\nReviews and Guides\n\u00a9 2024 Cond\u00e9 Nast. All rights reserved. WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond\u00e9 Nast. Ad Choices", "keywords": ["AI", "Machine Learning", "Language Models", "Artificial Intelligence", "AI Development", "Technology", "Innovation", "Natural Language Processing", "Text Analysis"], "language": "en", "translation": "To revisit this article, visit My Profile, then View saved stories.\nWhen OpenAI announced GPT-4, its latest large language model, last March, it sent shockwaves through the tech world. It was clearly more capable than anything seen before at chatting, coding, and solving all sorts of thorny problems\u2014including school homework.\nAnthropic, a rival to OpenAI, announced today that it has made its own AI advance that will upgrade chatbots and other use cases. But although the new model is the world\u2019s best by some measures, it\u2019s more of a step forward than a big leap.\nAnthropic\u2019s new model, called Claude 3.5 Sonnet, is an upgrade to its existing Claude 3 family of AI models. It is more adept at solving math, coding, and logic problems as measured by commonly used benchmarks. Anthropic says it is also a lot faster, better understands nuances in language, and even has a better sense of humor.\nThat\u2019s no doubt useful to people trying to build apps and services on top of Anthropic\u2019s AI models. But the company\u2019s news is also a reminder that the world is still waiting for another AI leap forward in AI akin to that delivered by GPT-4.Expectation has been building for OpenAI to release a sequel called GPT-5 for more than a year now, and the company\u2019s CEO, Sam Altman, has encouraged speculation that it will deliver another revolution in AI capabilities. GPT-4 cost more than $100 million to train, and GPT-5 is widely expected to be much larger and more expensive.\nAlthough OpenAI, Google, and other AI developers have released new models that out-do GPT-4, the world is still waiting for that next big leap. Progress in AI has lately become more incremental and more reliant on innovations in model design and training rather than brute-force scaling of model size and computation, as GPT-4 did.\nMichael Gerstenhaber, head of product at Anthropic, says the company\u2019s new Claude 3.5 Sonnet model is larger than its predecessor but draws much of its new competence from innovations in training. For example, the model was given feedback designed to improve its logical reasoning skills. Anthropic says that Claude 3.5 Sonnet outscores the best models from OpenAI, Google, and Facebook in popular AI benchmarks including GPQA, a graduate-level test of expertise in biology, physics, and chemistry; MMLU, a test covering computer science, history, and other topics; and HumanEval, a measure of coding proficiency. The improvements are a matter of a few percentage points though.This latest progress in AI might not be revolutionary but it is fast-paced: Anthropic only announced its previous generation of models three months ago. \u201cIf you look at the rate of change in intelligence you\u2019ll appreciate how fast we\u2019re moving,\u201d Gerstenhaber says.\nMore than a year after GPT-4 spurred a frenzy of new investment in AI, it may be turning out to be more difficult to produce big new leaps in machine intelligence. With GPT-4 and similar models trained on huge swathes of online text, imagery, and video, it is getting more difficult to find new sources of data to feed to machine-learning algorithms. Making models substantially larger, so they have more capacity to learn, is expected to cost billions of dollars. When OpenAI announced its own recent upgrade last month, with a model that has voice and visual capabilities called GPT-4o, the focus was on a more natural and humanlike interface rather than on substantially more clever problem-solving abilities.\nGauging the rate of progress in AI using conventional benchmarks like those touted by Anthropic for Claude can be misleading. AI developers are strongly incentivized to design their creations to score highly in these benchmarks, and the data used for these standardized tests can be swept into their training data. \u201cBenchmarks within the research community are riddled with data contamination, inconsistent rubrics and reporting, and unverified annotator expertise,\u201d says Summer Yue, research director at Scale AI, a company that helps many AI firms train their models.\nScale is developing new ways of measuring AI smarts through its Safety, Evaluations and Alignment Lab. This involves developing tests based on data that is kept secret and vetting the expertise of those who provide feedback on a model\u2019s capabilities.\nYue is hopeful that companies will increasingly seek to demonstrate their model\u2019s intelligence in more meaningful ways. She says those may include \u201cby showcasing real-world applications with measurable business impact, providing transparent performance metrics, case studies, and customer testimonials.\u201d\nAnthropic is touting such impacts for Claude 3.5 Sonnet. Gerstenhaber says that companies using the latest version have found its newfound responsiveness and problem-solving abilities beneficial. Customers include the investment firm Bridgewater Associates, which is using Claude to help with coding tasks. Some other financial firms, which Gerstenhaber declines to disclose, are using the model to provide investment advice. \u201cThe response during the early access period has been enormously positive,\u201d he says.\nIt\u2019s unclear how long the world must wait for that next big leap in AI. OpenAI has said it has started training its next big model. In the meantime, we will need to figure out new ways to measure how useful the technology really is.\nIn your inbox: Get Plaintext\u2014Steven Levy's long view on tech\nWelcome to the hellhole of programmatic advertising\nHow many EV charging stations does the US need to replace gas stations?\nA nonprofit tried to fix tech culture\u2014but lost control of its own\nIt's always sunny: Here are the best sunglasses for every adventure\nMore From WIRED\nReviews and Guides\n\u00a9 2024 Cond\u00e9 Nast. All rights reserved. WIRED may earn a portion of sales from products that are purchased through our site as part of our Affiliate Partnerships with retailers. The material on this site may not be reproduced, distributed, transmitted, cached or otherwise used, except with the prior written permission of Cond\u00e9 Nast. Ad Choices"}