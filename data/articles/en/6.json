{"id": 6, "title": "Instagram\u2019s \u2018Made with AI\u2019 label swapped out for \u2018AI info\u2019 after photographers\u2019 complaints", "timestamp": "2024-07-01T17:14:15Z", "content": "By  Richard Lawler, a senior editor following news across tech, culture, policy, and entertainment. He joined The Verge in 2021 after several years covering news at Engadget. \nOn Monday, Meta announced that it is \u201cupdating the \u2018Made with AI\u2019 label to \u2018AI info\u2019 across our apps, which people can click for more information,\u201d after people complained that their pictures had the tag applied incorrectly. Former White House photographer Pete Souza pointed out the tag popping up on an upload of a photo originally taken on film during a basketball game 40 years ago, speculating that using Adobe\u2019s cropping tool and flattening images might have triggered it.\n\u201cAs we\u2019ve said from the beginning, we\u2019re consistently improving our AI products, and we are working closely with our industry partners on our approach to AI labeling,\u201d said Meta spokesperson Kate McLaughlin. The new label is supposed to more accurately represent that the content may simply be modified rather than making it seem like it is entirely AI-generated.\nThe problem seems to be the metadata tools like Adobe Photoshop apply to images and how platforms interpret that. After Meta expanded its policies around labeling AI content, real-life pictures posted to platforms like Instagram, Facebook, and Threads were tagged \u201cMade with AI.\u201d \nHowever, Adobe points the finger at Meta and its decisions about how to present that metadata. \u201cWe know millions of users use AI today to perform the same aesthetic improvements to content as they did before AI. That\u2019s why when it comes to labeling AI, we believe platforms labeling content as being made with or generated by AI should only do so when an image is wholly AI generated,\u201d said Andy Parsons, Adobe senior director of the Content Authenticity Initiative (CAI), in a statement emailed to The Verge. \nYou may see the new labeling first on mobile apps and then the web view later, as McLaughlin tells The Verge it is starting to roll out across all surfaces. \nOnce you click the tag, it will still show the same message as the old label, which has a more detailed explanation of why it might have been applied and that it could cover images fully generated by AI or edited with tools that include AI tech, like Generative Fill. Metadata tagging tech like C2PA was supposed to make telling the difference between AI-generated and real images simpler and easier, but that future isn\u2019t here yet.\nAndy Parsons, Adobe:\nContent Credentials are an open technical standard designed to provide important information like a \u201cnutrition label\u201d for digital content such as the creator\u2019s name, the date an image was created, what tools were used and any edits that were made, including if generative AI was used. At Adobe we are excited by the promise and potential of the integration of AI into creative workflows to transform how people imagine, ideate, and create. In a world where anything digital can be edited, we recognize how important it is for Content Credentials to carry the context to make clear how content was created and edited, including if the content was wholly generated by a generative AI model. The Content Credentials standard was designed from the ground up to clearly express this context.\nThrough our role leading the Content Authenticity Initiative (CAI) and co-founding the Coalition for Content Provenance and Authenticity, we understand how to best express how content has been edited is an evolving process. We know millions of users use AI today to perform the same aesthetic improvements to content as they did before AI. That\u2019s why when it comes to labeling AI, we believe platforms labeling content as being made with or generated by AI should only do so when an image is wholly AI generated. That way, people will easily understand that the content they are viewing is entirely fake. If generative AI is only used in the editing process, the full context of Content Credentials should be viewable to provide deeper context into the authenticity, edits or underlying facts the creator may want to communicate.\nUpdate, July 2nd: Added statement from Adobe.\n / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.\nThe Verge is a vox media network\n\u00a9 2024 Vox Media, LLC. All Rights Reserved", "keywords": ["AI-generated content", "metadata", "Adobe Photoshop", "image editing", "digital authentication", "Content Authenticity Initiative"], "language": "en", "translation": "By  Richard Lawler, a senior editor following news across tech, culture, policy, and entertainment. He joined The Verge in 2021 after several years covering news at Engadget. \nOn Monday, Meta announced that it is \u201cupdating the \u2018Made with AI\u2019 label to \u2018AI info\u2019 across our apps, which people can click for more information,\u201d after people complained that their pictures had the tag applied incorrectly. Former White House photographer Pete Souza pointed out the tag popping up on an upload of a photo originally taken on film during a basketball game 40 years ago, speculating that using Adobe\u2019s cropping tool and flattening images might have triggered it.\n\u201cAs we\u2019ve said from the beginning, we\u2019re consistently improving our AI products, and we are working closely with our industry partners on our approach to AI labeling,\u201d said Meta spokesperson Kate McLaughlin. The new label is supposed to more accurately represent that the content may simply be modified rather than making it seem like it is entirely AI-generated.\nThe problem seems to be the metadata tools like Adobe Photoshop apply to images and how platforms interpret that. After Meta expanded its policies around labeling AI content, real-life pictures posted to platforms like Instagram, Facebook, and Threads were tagged \u201cMade with AI.\u201d \nHowever, Adobe points the finger at Meta and its decisions about how to present that metadata. \u201cWe know millions of users use AI today to perform the same aesthetic improvements to content as they did before AI. That\u2019s why when it comes to labeling AI, we believe platforms labeling content as being made with or generated by AI should only do so when an image is wholly AI generated,\u201d said Andy Parsons, Adobe senior director of the Content Authenticity Initiative (CAI), in a statement emailed to The Verge. \nYou may see the new labeling first on mobile apps and then the web view later, as McLaughlin tells The Verge it is starting to roll out across all surfaces. \nOnce you click the tag, it will still show the same message as the old label, which has a more detailed explanation of why it might have been applied and that it could cover images fully generated by AI or edited with tools that include AI tech, like Generative Fill. Metadata tagging tech like C2PA was supposed to make telling the difference between AI-generated and real images simpler and easier, but that future isn\u2019t here yet.\nAndy Parsons, Adobe:\nContent Credentials are an open technical standard designed to provide important information like a \u201cnutrition label\u201d for digital content such as the creator\u2019s name, the date an image was created, what tools were used and any edits that were made, including if generative AI was used. At Adobe we are excited by the promise and potential of the integration of AI into creative workflows to transform how people imagine, ideate, and create. In a world where anything digital can be edited, we recognize how important it is for Content Credentials to carry the context to make clear how content was created and edited, including if the content was wholly generated by a generative AI model. The Content Credentials standard was designed from the ground up to clearly express this context.\nThrough our role leading the Content Authenticity Initiative (CAI) and co-founding the Coalition for Content Provenance and Authenticity, we understand how to best express how content has been edited is an evolving process. We know millions of users use AI today to perform the same aesthetic improvements to content as they did before AI. That\u2019s why when it comes to labeling AI, we believe platforms labeling content as being made with or generated by AI should only do so when an image is wholly AI generated. That way, people will easily understand that the content they are viewing is entirely fake. If generative AI is only used in the editing process, the full context of Content Credentials should be viewable to provide deeper context into the authenticity, edits or underlying facts the creator may want to communicate.\nUpdate, July 2nd: Added statement from Adobe.\n / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.\nThe Verge is a vox media network\n\u00a9 2024 Vox Media, LLC. All Rights Reserved"}