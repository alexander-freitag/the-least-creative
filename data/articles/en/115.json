{"id": 115, "title": "Typing to AI assistants might be the way to go", "timestamp": "2024-06-22T12:00:00Z", "content": "By  Victoria Song, a senior reporter focusing on wearables, health tech, and more with 12 years of experience. Before coming to The Verge, she worked for Gizmodo and PC Magazine.\nThere\u2019s a time and place for everything. In the privacy of my own home, I\u2019ve got no problem saying \u201chey\u201d to Google, Alexa, Siri, Meta, and on occasion, Bixby. But out in public? Where other people can perceive me? I\u2019d rather crawl under a rock.\nThis has been one of my biggest problems with AI gadgets these past few months. All of them seem convinced that the best way to interact with AI assistants is to actually talk to them, not unlike the movie Her. In reality, I\u2019ve rarely seen my friends and family use their phone\u2019s assistants when we\u2019re hanging out privately and never out in public. So it felt like a tiny \u201cAha!\u201d moment when, during last week\u2019s WWDC keynote, Apple mentioned that iOS 18 will let you type to Siri instead.\nTechnically, you can already do this via the iPhone\u2019s accessibility settings. (Go to Accessibility > Siri > Type to Siri.) This brings up a fairly bare-bones window and keyboard for you to type a command in. But in iOS 18, Apple embraces the feature, letting you double-tap the bottom of the screen to bring up a Siri keyboard. You\u2019ll also be able to see quick suggestions that you can simply tap instead of having to type (or say) a whole query out. \nThere are a ton of reasons why this just makes sense. While digital assistants have gotten better at understanding commands, it\u2019s still tough to talk to them naturally. At home, I feel myself affecting a certain pitch and tone when I use a wake word. I find myself thinking beforehand about how I want to word a query. In spite of myself, I still occasionally botch it when asking Google to turn my living room lights to 25 percent brightness. I feel even more self-conscious if I have to do this in public.\nOutside, it\u2019s also incredibly noisy. While testing the Ray-Ban Meta smart glasses\u2019 multimodal AI features, I often had the AI tell me that the glasses couldn\u2019t hear me properly. Either my environment was too loud, or I was subconsciously so embarrassed I spoke too quietly for the device to clearly pick up what I was saying. That led to a ton of frustration, which, in turn, caused me to whip out my phone \u2014 the exact opposite of what AI hardware wants me to do.\nIt\u2019s not just newfangled AI gadgets, either. Speaking into a smartwatch looks cool if you\u2019re James Bond. Most of us are not. If anything, most people I see doing it look a little confused and frustrated. Is this vain? Yes. But self-consciousness is a big reason why people may be hesitant to experiment with voice-controlled assistants when they\u2019re out and about. A 2018 PwC survey into voice assistant use found that 74 percent of consumers prefer to use voice assistants at home, with participants saying that using them in public \u201cjust looks weird.\u201d In the same survey, lack of trust was identified as another major hurdle to using voice assistants in general \u2014 people just didn\u2019t believe that a voice assistant would correctly understand commands. If experience tells you an AI assistant likely won\u2019t understand you, why would you bother trying to use it in a place where you\u2019re more likely to be judged? (Also, imagine saying \u201cHey Siri\u201d and activating your fellow commuters\u2019 iPhones. New nightmare unlocked.)\nTech logistics aside, typing to your AI assistant also affords you a greater degree of privacy. I don\u2019t need people to know what I\u2019m doing on my phone, even if it\u2019s something as innocuous as playing a song or setting a timer. I especially don\u2019t want to dictate texts aloud when others can hear me. Typing those kinds of queries allows me to keep my business to myself \u2014 and, for that, I\u2019m happy to sacrifice some hands-free capabilities.\nI\u2019m not denying that there are reasons why you might need to speak to an assistant, even in public settings. Voice commands are especially useful if you don\u2019t have use of your hands or are driving a car. But having multiple ways to interact with AI assistants lets them fit more seamlessly into how we want to use our gadgets \u2014 instead of forcing everyone to adopt new paradigms. Maybe one day, it won\u2019t feel weird to talk to a chatbot out loud while walking down the street. For most people, that day isn\u2019t today. And until such a time comes, I\u2019ll happily type to Siri instead.\n / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.\nThe Verge is a vox media network\n\u00a9 2024 Vox Media, LLC. All Rights Reserved", "keywords": ["Health Tech", "Wearables", "AI Assistants", "Voice Control", "Privacy", "Siri", "iOS"], "language": "en", "translation": "By  Victoria Song, a senior reporter focusing on wearables, health tech, and more with 12 years of experience. Before coming to The Verge, she worked for Gizmodo and PC Magazine.\nThere\u2019s a time and place for everything. In the privacy of my own home, I\u2019ve got no problem saying \u201chey\u201d to Google, Alexa, Siri, Meta, and on occasion, Bixby. But out in public? Where other people can perceive me? I\u2019d rather crawl under a rock.\nThis has been one of my biggest problems with AI gadgets these past few months. All of them seem convinced that the best way to interact with AI assistants is to actually talk to them, not unlike the movie Her. In reality, I\u2019ve rarely seen my friends and family use their phone\u2019s assistants when we\u2019re hanging out privately and never out in public. So it felt like a tiny \u201cAha!\u201d moment when, during last week\u2019s WWDC keynote, Apple mentioned that iOS 18 will let you type to Siri instead.\nTechnically, you can already do this via the iPhone\u2019s accessibility settings. (Go to Accessibility > Siri > Type to Siri.) This brings up a fairly bare-bones window and keyboard for you to type a command in. But in iOS 18, Apple embraces the feature, letting you double-tap the bottom of the screen to bring up a Siri keyboard. You\u2019ll also be able to see quick suggestions that you can simply tap instead of having to type (or say) a whole query out. \nThere are a ton of reasons why this just makes sense. While digital assistants have gotten better at understanding commands, it\u2019s still tough to talk to them naturally. At home, I feel myself affecting a certain pitch and tone when I use a wake word. I find myself thinking beforehand about how I want to word a query. In spite of myself, I still occasionally botch it when asking Google to turn my living room lights to 25 percent brightness. I feel even more self-conscious if I have to do this in public.\nOutside, it\u2019s also incredibly noisy. While testing the Ray-Ban Meta smart glasses\u2019 multimodal AI features, I often had the AI tell me that the glasses couldn\u2019t hear me properly. Either my environment was too loud, or I was subconsciously so embarrassed I spoke too quietly for the device to clearly pick up what I was saying. That led to a ton of frustration, which, in turn, caused me to whip out my phone \u2014 the exact opposite of what AI hardware wants me to do.\nIt\u2019s not just newfangled AI gadgets, either. Speaking into a smartwatch looks cool if you\u2019re James Bond. Most of us are not. If anything, most people I see doing it look a little confused and frustrated. Is this vain? Yes. But self-consciousness is a big reason why people may be hesitant to experiment with voice-controlled assistants when they\u2019re out and about. A 2018 PwC survey into voice assistant use found that 74 percent of consumers prefer to use voice assistants at home, with participants saying that using them in public \u201cjust looks weird.\u201d In the same survey, lack of trust was identified as another major hurdle to using voice assistants in general \u2014 people just didn\u2019t believe that a voice assistant would correctly understand commands. If experience tells you an AI assistant likely won\u2019t understand you, why would you bother trying to use it in a place where you\u2019re more likely to be judged? (Also, imagine saying \u201cHey Siri\u201d and activating your fellow commuters\u2019 iPhones. New nightmare unlocked.)\nTech logistics aside, typing to your AI assistant also affords you a greater degree of privacy. I don\u2019t need people to know what I\u2019m doing on my phone, even if it\u2019s something as innocuous as playing a song or setting a timer. I especially don\u2019t want to dictate texts aloud when others can hear me. Typing those kinds of queries allows me to keep my business to myself \u2014 and, for that, I\u2019m happy to sacrifice some hands-free capabilities.\nI\u2019m not denying that there are reasons why you might need to speak to an assistant, even in public settings. Voice commands are especially useful if you don\u2019t have use of your hands or are driving a car. But having multiple ways to interact with AI assistants lets them fit more seamlessly into how we want to use our gadgets \u2014 instead of forcing everyone to adopt new paradigms. Maybe one day, it won\u2019t feel weird to talk to a chatbot out loud while walking down the street. For most people, that day isn\u2019t today. And until such a time comes, I\u2019ll happily type to Siri instead.\n / Sign up for Verge Deals to get deals on products we've tested sent to your inbox weekly.\nThe Verge is a vox media network\n\u00a9 2024 Vox Media, LLC. All Rights Reserved"}